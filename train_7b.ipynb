{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U git+https://github.com/lvwerra/trl.git\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q langchain\n",
    "!pip install -q einops\n",
    "!pip install -q -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 14:03:48.232697: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-16 14:03:48.995726: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-07-16 14:03:48.995874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-07-16 14:03:48.995884: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from peft import LoraConfig, get_pet_model, prepare_for_intk_training\n",
    "\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /wandb/ wasn't writable, using system temp directory.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /wandb/ wasn't writable, using system temp directory\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /wandb/ wasn't writable, using system temp directory\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseshurajup\u001b[0m (\u001b[33mmodel-masters\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/healthpulse/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "api_key = \"894fc801a85dc79ac36d24f3f2ac70cebe580ecf\"\n",
    "wandb.login(key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/healthpulse/.cache/huggingface/datasets/csv/default-574bb77c03e0b31b/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc824308786d47f69786682b60e90054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_PROJECT\"] = \"llm\"\n",
    "data = load_dataset(\"csv\", data_files=\"/datadrive1/input/wikipedia-stem-1k/stem_1k_v1.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D, E]\n",
    "\n",
    "Question: {prompt}\\n\n",
    "A) {a}\\n\n",
    "B) {b}\\n\n",
    "C) {c}\\n\n",
    "D) {d}\\n\n",
    "E) {e}\\n\n",
    "\n",
    "Answer: {answer}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['prompt', 'a', 'b', 'c', 'd', 'e', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D, E]\n",
       "\n",
       "Question: Who is the dean of the University of Central Florida College of Engineering and Computer Science?\n",
       "\n",
       "A) John Doe\n",
       "\n",
       "B) Michael Georgiopoulos\n",
       "\n",
       "C) Jane Smith\n",
       "\n",
       "D) Robert Johnson\n",
       "\n",
       "E) David Brown\n",
       "\n",
       "\n",
       "Answer: B"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = data['train'][0]\n",
    "display(Markdown(prompt.format(prompt=sample['prompt'], \n",
    "                               a=sample['A'], \n",
    "                               b=sample['B'], \n",
    "                               c=sample['C'], \n",
    "                               d=sample['D'], \n",
    "                               e=sample['E'], \n",
    "                               answer=sample['answer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(example):\n",
    "    text = prompt.format(prompt=example['prompt'], \n",
    "                         a=example['A'], \n",
    "                         b=example['B'], \n",
    "                         c=example['C'], \n",
    "                         d=example['D'], \n",
    "                         e=example['E'], \n",
    "                         answer=example['answer'])\n",
    "    return {\"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3164de04758b403a974db4721b47f7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.map(format_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequence_lengths(data, split='train', max_length=2048):\n",
    "    sequence_lengths = []\n",
    "    keep_indices = []\n",
    "\n",
    "    # Loop over the dataset and get the lengths of text sequences\n",
    "    for i, example in enumerate(data[split]):\n",
    "        sequence_lengths.append(len(example['text']))\n",
    "        if sequence_lengths[i] < max_length:\n",
    "            keep_indices.append(i)\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.hist(sequence_lengths, bins=30)\n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Text Sequence Lengths')\n",
    "    plt.show()\n",
    "\n",
    "    return keep_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_indices_train = plot_sequence_lengths(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'] = data['train'].select(keep_indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Salesforce/xgen-7b-4k-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3397c92bdb4a09966774e75cb664bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenization_xgen.py:   0%|          | 0.00/8.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/xgen-7b-4k-base:\n",
      "- tokenization_xgen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc55d07e1c44f75947267c9bdf1ddeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/510 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9b907c37ba482982c2956c6cf76615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834b8f1d82df44d8a5b777d0070a6046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8979fb1e1c48c5b0ace83410585f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00003.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153d2728237f4bd58bfae1e8d33d1e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00003.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb24768728fe43e7bc453bb273f86492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00003.bin:   0%|          | 0.00/7.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae3b92c663746aea69af7a9c9101b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a64e4749d394d93bd75ead9c6cb6bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    "    # quantization_config=bnb_config,\n",
    "    # trust_remote_code=True,\n",
    "    #revision=\"2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5\" # Using this version because running the new version gives error \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: peft 0.4.0.dev0\n",
      "Uninstalling peft-0.4.0.dev0:\n",
      "  Successfully uninstalled peft-0.4.0.dev0\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-rmxb6d1g\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-rmxb6d1g\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 42ab10699bcb9fa5e1092373959995930a170f43\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (21.3)\n",
      "Requirement already satisfied: psutil in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (2.0.1)\n",
      "Requirement already satisfied: transformers in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (4.31.0.dev0)\n",
      "Requirement already satisfied: accelerate in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (0.22.0.dev0)\n",
      "Requirement already satisfied: safetensors in /anaconda/envs/py38_default/lib/python3.8/site-packages (from peft==0.4.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from packaging>=20.0->peft==0.4.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: filelock in /anaconda/envs/py38_default/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /anaconda/envs/py38_default/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (4.6.3)\n",
      "Requirement already satisfied: sympy in /anaconda/envs/py38_default/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /anaconda/envs/py38_default/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers->peft==0.4.0.dev0) (0.15.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers->peft==0.4.0.dev0) (2023.3.23)\n",
      "Requirement already satisfied: requests in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers->peft==0.4.0.dev0) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers->peft==0.4.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers->peft==0.4.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /anaconda/envs/py38_default/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0.dev0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0.dev0) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft==0.4.0.dev0) (1.2.1)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=72137 sha256=cd3dfd0b60afd3c6670925a32426b6f23d390819c04af5a7a651647edef24a35\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3jm7rczf/wheels/95/fe/57/a484616f9bd99820cb946c7c3d2b1b492423b504356b0797dd\n",
      "Successfully built peft\n",
      "Installing collected packages: peft\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fschat 0.2.18 requires transformers<4.29.0,>=4.28.0, but you have transformers 4.31.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed peft-0.4.0.dev0\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y peft\n",
    "\n",
    "! pip install -U git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 14:49:26.404276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-16 14:49:27.152044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-07-16 14:49:27.152201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-07-16 14:49:27.152212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import peft\n",
    "peft.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "#prepare_for_int8_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    #target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/datadrive1/train_models/xgen-4k\", \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=20,\n",
    "    logging_strategy=\"steps\",\n",
    "    max_steps=1000,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    fp16=True,\n",
    "    run_name=\"baseline-falcon-sft\",\n",
    "    warmup_ratio=0.1,\n",
    "    save_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     quantization_config=bnb_config,\n",
    "#     trust_remote_code=True,\n",
    "#     #revision=\"2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5\" # Using this version because running the new version gives error \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faab33e116ce455c9c8885ef06eace52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "supervised_finetuning_trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    #packing=True,\n",
    "    data_collator=DataCollatorForCompletionOnlyLM(tokenizer=tokenizer, \n",
    "                                                  response_template=\"Answer:\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadrive1\n"
     ]
    }
   ],
   "source": [
    "%cd /datadrive1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! rm -rf train_models/runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  69/1000 01:25 < 19:53, 0.78 it/s, Epoch 0.54/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.930800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.566300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.448300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m supervised_finetuning_trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1544\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1808\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1809\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1811\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1812\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1813\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1814\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer.py:2654\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2651\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2653\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2654\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2657\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2678\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2679\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2680\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/accelerate/utils/operations.py:581\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m model_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/accelerate/utils/operations.py:569\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_to_fp32(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_autocast\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/peft/peft_model.py:924\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mforward in MPTForCausalLM does not support inputs_embeds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    914\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_model(\n\u001b[1;32m    915\u001b[0m             input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    916\u001b[0m             attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    922\u001b[0m         )\n\u001b[0;32m--> 924\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_model(\n\u001b[1;32m    925\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    926\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    927\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    928\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m    929\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    930\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    931\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    932\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    935\u001b[0m batch_size \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[39m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:756\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    753\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m    755\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 756\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m    757\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    758\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    759\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    760\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    761\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    762\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    763\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    764\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    765\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    766\u001b[0m )\n\u001b[1;32m    768\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    769\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:636\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[39mreturn\u001b[39;00m module(\u001b[39m*\u001b[39minputs, output_attentions, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    634\u001b[0m         \u001b[39mreturn\u001b[39;00m custom_forward\n\u001b[0;32m--> 636\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mcheckpoint\u001b[39m.\u001b[39;49mcheckpoint(\n\u001b[1;32m    637\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    638\u001b[0m         hidden_states,\n\u001b[1;32m    639\u001b[0m         attention_mask,\n\u001b[1;32m    640\u001b[0m         position_ids,\n\u001b[1;32m    641\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    642\u001b[0m     )\n\u001b[1;32m    643\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    645\u001b[0m         hidden_states,\n\u001b[1;32m    646\u001b[0m         attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    650\u001b[0m         use_cache\u001b[39m=\u001b[39muse_cache,\n\u001b[1;32m    651\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/utils/checkpoint.py:249\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnexpected keyword arguments: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m kwargs))\n\u001b[1;32m    248\u001b[0m \u001b[39mif\u001b[39;00m use_reentrant:\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mreturn\u001b[39;00m CheckpointFunction\u001b[39m.\u001b[39;49mapply(function, preserve, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m _checkpoint_without_reentrant(\n\u001b[1;32m    252\u001b[0m         function,\n\u001b[1;32m    253\u001b[0m         preserve,\n\u001b[1;32m    254\u001b[0m         \u001b[39m*\u001b[39margs,\n\u001b[1;32m    255\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/utils/checkpoint.py:107\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m ctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39m*\u001b[39mtensor_inputs)\n\u001b[1;32m    106\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 107\u001b[0m     outputs \u001b[39m=\u001b[39m run_function(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:632\u001b[0m, in \u001b[0;36mLlamaModel.forward.<locals>.create_custom_forward.<locals>.custom_forward\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcustom_forward\u001b[39m(\u001b[39m*\u001b[39minputs):\n\u001b[1;32m    631\u001b[0m     \u001b[39m# None for past_key_value\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m     \u001b[39mreturn\u001b[39;00m module(\u001b[39m*\u001b[39;49minputs, output_attentions, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:372\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    370\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    371\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 372\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[1;32m    373\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    375\u001b[0m outputs \u001b[39m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:204\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_proj(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgate_proj(x)) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup_proj(x))\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/bitsandbytes/nn/modules.py:221\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_dtype)\n\u001b[1;32m    220\u001b[0m bias \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_dtype)\n\u001b[0;32m--> 221\u001b[0m out \u001b[39m=\u001b[39m bnb\u001b[39m.\u001b[39;49mmatmul_4bit(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mt(), bias\u001b[39m=\u001b[39;49mbias, quant_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mquant_state)\n\u001b[1;32m    223\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mto(inp_dtype)\n\u001b[1;32m    225\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:579\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    578\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m MatMul4Bit\u001b[39m.\u001b[39;49mapply(A, B, out, bias, quant_state)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:516\u001b[0m, in \u001b[0;36mMatMul4Bit.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mempty(A\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m B_shape[:\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mA\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mA\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    514\u001b[0m \u001b[39m# 1. Dequantize\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39m# 2. MatmulnN\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mlinear(A, F\u001b[39m.\u001b[39;49mdequantize_4bit(B, state)\u001b[39m.\u001b[39;49mto(A\u001b[39m.\u001b[39;49mdtype)\u001b[39m.\u001b[39;49mt(), bias)\n\u001b[1;32m    518\u001b[0m \u001b[39m# 3. Save state\u001b[39;00m\n\u001b[1;32m    519\u001b[0m ctx\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m state\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "supervised_finetuning_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
